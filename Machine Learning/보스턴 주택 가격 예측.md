# 보스톤 주택 가격 예측

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```

```python
from sklearn.datasets import load_boston
```

## 1. 데이터 탐색

```
CRIM     per capita crime rate by town
ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
INDUS    proportion of non-retail business acres per town
CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
NOX      nitric oxides concentration (parts per 10 million)
RM       average number of rooms per dwelling
AGE      proportion of owner-occupied units built prior to 1940
DIS      weighted distances to five Boston employment centres
RAD      index of accessibility to radial highways
TAX      full-value property-tax rate per $10,000
PTRATIO  pupil-teacher ratio by town
B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
LSTAT    % lower status of the population
MEDV     Median value of owner-occupied homes in $1000's
```

- CRIM: 지역별 범죄 발생률
  
- ZN: 25,000평방피트를 초과하는 거주 지역의 비율
  
- NDUS: 비상업 지역 넓이 비율
  
- CHAS: 찰스강에 대한 더미 변수(강의 경계에 위치한 경우는 1, 아니면 0)
  
- NOX: 일산화질소 농도
  
- RM: 거주할 수 있는 방 개수
  
- AGE: 1940년 이전에 건축된 소유 주택의 비율
  
- DIS: 5개 주요 고용센터까지의 가중 거리
  
- RAD: 고속도로 접근 용이도
  
- TAX: 10,000달러당 재산세율
  
- PTRATIO: 지역의 교사와 학생 수 비율
  
- B: 지역의 흑인 거주 비율
  
- LSTAT: 하위 계층의 비율
  
- MEDV: 본인 소유의 주택 가격(중앙값)
  

- DataFrame으로 준비
  

```python
boston_data = load_boston()
```

```
C:\Users\Playdata\anaconda3_NR\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.

    The Boston housing prices dataset has an ethical problem. You can refer to
    the documentation of this function for further details.

    The scikit-learn maintainers therefore strongly discourage the use of this
    dataset unless the purpose of the code is to study and educate about
    ethical issues in data science and machine learning.

    In this special case, you can fetch the dataset from the original
    source::

        import pandas as pd
        import numpy as np


        data_url = "http://lib.stat.cmu.edu/datasets/boston"
        raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
        target = raw_df.values[1::2, 2]

    Alternative datasets include the California housing dataset (i.e.
    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing
    dataset. You can load the datasets as follows::

        from sklearn.datasets import fetch_california_housing
        housing = fetch_california_housing()

    for the California housing dataset and::

        from sklearn.datasets import fetch_openml
        housing = fetch_openml(name="house_prices", as_frame=True)

    for the Ames housing dataset.

  warnings.warn(msg, category=FutureWarning)
```

```python
df = pd.DataFrame(boston_data.data, columns = boston_data.feature_names)
df['PRICE'] = boston_data.target
df.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>PRICE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>

```python
boston_df = pd.DataFrame(boston_data['data'], columns = boston_data['feature_names'])
```

```python
type(boston_data['data']), boston_data['data'].shape
```

```
(numpy.ndarray, (506, 13))
```

```python
boston_df['target'] = boston_data['target']
```

```python
boston_df.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>

- 누락 데이터 확인

```python
boston_df.info()
```

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 506 entries, 0 to 505
Data columns (total 14 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   CRIM     506 non-null    float64
 1   ZN       506 non-null    float64
 2   INDUS    506 non-null    float64
 3   CHAS     506 non-null    float64
 4   NOX      506 non-null    float64
 5   RM       506 non-null    float64
 6   AGE      506 non-null    float64
 7   DIS      506 non-null    float64
 8   RAD      506 non-null    float64
 9   TAX      506 non-null    float64
 10  PTRATIO  506 non-null    float64
 11  B        506 non-null    float64
 12  LSTAT    506 non-null    float64
 13  target   506 non-null    float64
dtypes: float64(14)
memory usage: 55.5 KB
```

```python
boston_df.isnull().sum()
```

```
CRIM       0
ZN         0
INDUS      0
CHAS       0
NOX        0
RM         0
AGE        0
DIS        0
RAD        0
TAX        0
PTRATIO    0
B          0
LSTAT      0
target     0
dtype: int64
```

- 통계 정보

```python
boston_df.describe()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
      <td>506.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.613524</td>
      <td>11.363636</td>
      <td>11.136779</td>
      <td>0.069170</td>
      <td>0.554695</td>
      <td>6.284634</td>
      <td>68.574901</td>
      <td>3.795043</td>
      <td>9.549407</td>
      <td>408.237154</td>
      <td>18.455534</td>
      <td>356.674032</td>
      <td>12.653063</td>
      <td>22.532806</td>
    </tr>
    <tr>
      <th>std</th>
      <td>8.601545</td>
      <td>23.322453</td>
      <td>6.860353</td>
      <td>0.253994</td>
      <td>0.115878</td>
      <td>0.702617</td>
      <td>28.148861</td>
      <td>2.105710</td>
      <td>8.707259</td>
      <td>168.537116</td>
      <td>2.164946</td>
      <td>91.294864</td>
      <td>7.141062</td>
      <td>9.197104</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.006320</td>
      <td>0.000000</td>
      <td>0.460000</td>
      <td>0.000000</td>
      <td>0.385000</td>
      <td>3.561000</td>
      <td>2.900000</td>
      <td>1.129600</td>
      <td>1.000000</td>
      <td>187.000000</td>
      <td>12.600000</td>
      <td>0.320000</td>
      <td>1.730000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.082045</td>
      <td>0.000000</td>
      <td>5.190000</td>
      <td>0.000000</td>
      <td>0.449000</td>
      <td>5.885500</td>
      <td>45.025000</td>
      <td>2.100175</td>
      <td>4.000000</td>
      <td>279.000000</td>
      <td>17.400000</td>
      <td>375.377500</td>
      <td>6.950000</td>
      <td>17.025000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.256510</td>
      <td>0.000000</td>
      <td>9.690000</td>
      <td>0.000000</td>
      <td>0.538000</td>
      <td>6.208500</td>
      <td>77.500000</td>
      <td>3.207450</td>
      <td>5.000000</td>
      <td>330.000000</td>
      <td>19.050000</td>
      <td>391.440000</td>
      <td>11.360000</td>
      <td>21.200000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.677083</td>
      <td>12.500000</td>
      <td>18.100000</td>
      <td>0.000000</td>
      <td>0.624000</td>
      <td>6.623500</td>
      <td>94.075000</td>
      <td>5.188425</td>
      <td>24.000000</td>
      <td>666.000000</td>
      <td>20.200000</td>
      <td>396.225000</td>
      <td>16.955000</td>
      <td>25.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>88.976200</td>
      <td>100.000000</td>
      <td>27.740000</td>
      <td>1.000000</td>
      <td>0.871000</td>
      <td>8.780000</td>
      <td>100.000000</td>
      <td>12.126500</td>
      <td>24.000000</td>
      <td>711.000000</td>
      <td>22.000000</td>
      <td>396.900000</td>
      <td>37.970000</td>
      <td>50.000000</td>
    </tr>
  </tbody>
</table>
</div>

- 시각화

```python
h = df.hist(bins=50, figsize=(20, 15))
```

![image](https://user-images.githubusercontent.com/84713532/205041156-db6999c4-b0d5-4c87-9f11-52d703cf524a.png)


- 상관계수

```python
boston_corr = boston_df.corr()
boston_corr
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>1.000000</td>
      <td>-0.200469</td>
      <td>0.406583</td>
      <td>-0.055892</td>
      <td>0.420972</td>
      <td>-0.219247</td>
      <td>0.352734</td>
      <td>-0.379670</td>
      <td>0.625505</td>
      <td>0.582764</td>
      <td>0.289946</td>
      <td>-0.385064</td>
      <td>0.455621</td>
      <td>-0.388305</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>-0.200469</td>
      <td>1.000000</td>
      <td>-0.533828</td>
      <td>-0.042697</td>
      <td>-0.516604</td>
      <td>0.311991</td>
      <td>-0.569537</td>
      <td>0.664408</td>
      <td>-0.311948</td>
      <td>-0.314563</td>
      <td>-0.391679</td>
      <td>0.175520</td>
      <td>-0.412995</td>
      <td>0.360445</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.406583</td>
      <td>-0.533828</td>
      <td>1.000000</td>
      <td>0.062938</td>
      <td>0.763651</td>
      <td>-0.391676</td>
      <td>0.644779</td>
      <td>-0.708027</td>
      <td>0.595129</td>
      <td>0.720760</td>
      <td>0.383248</td>
      <td>-0.356977</td>
      <td>0.603800</td>
      <td>-0.483725</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>-0.055892</td>
      <td>-0.042697</td>
      <td>0.062938</td>
      <td>1.000000</td>
      <td>0.091203</td>
      <td>0.091251</td>
      <td>0.086518</td>
      <td>-0.099176</td>
      <td>-0.007368</td>
      <td>-0.035587</td>
      <td>-0.121515</td>
      <td>0.048788</td>
      <td>-0.053929</td>
      <td>0.175260</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>0.420972</td>
      <td>-0.516604</td>
      <td>0.763651</td>
      <td>0.091203</td>
      <td>1.000000</td>
      <td>-0.302188</td>
      <td>0.731470</td>
      <td>-0.769230</td>
      <td>0.611441</td>
      <td>0.668023</td>
      <td>0.188933</td>
      <td>-0.380051</td>
      <td>0.590879</td>
      <td>-0.427321</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>-0.219247</td>
      <td>0.311991</td>
      <td>-0.391676</td>
      <td>0.091251</td>
      <td>-0.302188</td>
      <td>1.000000</td>
      <td>-0.240265</td>
      <td>0.205246</td>
      <td>-0.209847</td>
      <td>-0.292048</td>
      <td>-0.355501</td>
      <td>0.128069</td>
      <td>-0.613808</td>
      <td>0.695360</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.352734</td>
      <td>-0.569537</td>
      <td>0.644779</td>
      <td>0.086518</td>
      <td>0.731470</td>
      <td>-0.240265</td>
      <td>1.000000</td>
      <td>-0.747881</td>
      <td>0.456022</td>
      <td>0.506456</td>
      <td>0.261515</td>
      <td>-0.273534</td>
      <td>0.602339</td>
      <td>-0.376955</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-0.379670</td>
      <td>0.664408</td>
      <td>-0.708027</td>
      <td>-0.099176</td>
      <td>-0.769230</td>
      <td>0.205246</td>
      <td>-0.747881</td>
      <td>1.000000</td>
      <td>-0.494588</td>
      <td>-0.534432</td>
      <td>-0.232471</td>
      <td>0.291512</td>
      <td>-0.496996</td>
      <td>0.249929</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.625505</td>
      <td>-0.311948</td>
      <td>0.595129</td>
      <td>-0.007368</td>
      <td>0.611441</td>
      <td>-0.209847</td>
      <td>0.456022</td>
      <td>-0.494588</td>
      <td>1.000000</td>
      <td>0.910228</td>
      <td>0.464741</td>
      <td>-0.444413</td>
      <td>0.488676</td>
      <td>-0.381626</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>0.582764</td>
      <td>-0.314563</td>
      <td>0.720760</td>
      <td>-0.035587</td>
      <td>0.668023</td>
      <td>-0.292048</td>
      <td>0.506456</td>
      <td>-0.534432</td>
      <td>0.910228</td>
      <td>1.000000</td>
      <td>0.460853</td>
      <td>-0.441808</td>
      <td>0.543993</td>
      <td>-0.468536</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>0.289946</td>
      <td>-0.391679</td>
      <td>0.383248</td>
      <td>-0.121515</td>
      <td>0.188933</td>
      <td>-0.355501</td>
      <td>0.261515</td>
      <td>-0.232471</td>
      <td>0.464741</td>
      <td>0.460853</td>
      <td>1.000000</td>
      <td>-0.177383</td>
      <td>0.374044</td>
      <td>-0.507787</td>
    </tr>
    <tr>
      <th>B</th>
      <td>-0.385064</td>
      <td>0.175520</td>
      <td>-0.356977</td>
      <td>0.048788</td>
      <td>-0.380051</td>
      <td>0.128069</td>
      <td>-0.273534</td>
      <td>0.291512</td>
      <td>-0.444413</td>
      <td>-0.441808</td>
      <td>-0.177383</td>
      <td>1.000000</td>
      <td>-0.366087</td>
      <td>0.333461</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>0.455621</td>
      <td>-0.412995</td>
      <td>0.603800</td>
      <td>-0.053929</td>
      <td>0.590879</td>
      <td>-0.613808</td>
      <td>0.602339</td>
      <td>-0.496996</td>
      <td>0.488676</td>
      <td>0.543993</td>
      <td>0.374044</td>
      <td>-0.366087</td>
      <td>1.000000</td>
      <td>-0.737663</td>
    </tr>
    <tr>
      <th>target</th>
      <td>-0.388305</td>
      <td>0.360445</td>
      <td>-0.483725</td>
      <td>0.175260</td>
      <td>-0.427321</td>
      <td>0.695360</td>
      <td>-0.376955</td>
      <td>0.249929</td>
      <td>-0.381626</td>
      <td>-0.468536</td>
      <td>-0.507787</td>
      <td>0.333461</td>
      <td>-0.737663</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

```python
import seaborn as sns

f, ax = plt.subplots(figsize=(13, 10))
sns.heatmap(boston_corr, annot = True)
```

```
<AxesSubplot:>
```

![image](https://user-images.githubusercontent.com/84713532/205041215-cb539a37-758f-44af-913c-bcb883364244.png)


```python
df.plot(kind = 'scatter', x = 'LSTAT', y = 'PRICE')
```

```
<AxesSubplot:xlabel='LSTAT', ylabel='PRICE'>
```

![image](https://user-images.githubusercontent.com/84713532/205041255-4adee6a4-d9bf-4e4c-86c7-483be1b0e7d4.png)


```python
df.plot(kind = 'scatter', x = 'RM', y = 'PRICE')
```

```
<AxesSubplot:xlabel='RM', ylabel='PRICE'>
```

![image](https://user-images.githubusercontent.com/84713532/205041276-1306b38d-02dd-400f-b592-0f83875601d8.png)


## 2. 데이터 준비

```python
from sklearn.model_selection import train_test_split
```

```python
X = df.drop('PRICE', axis = 1)
y = df['PRICE']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)
```

```python
# 전체 데이터를 무작위로 섞은 후에 훈련 데이터와 테스트 데이터를 나눠서 반환
X_train, X_test, y_train, y_test = train_test_split(boston_data['data'], boston_data['target'], test_size = 0.2, random_state = 42)  # numpy 데이터를 넣어주는 것이 좋음
```

```python
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
```

```
(404, 13) (102, 13) (404,) (102,)
```

## 3. 모델 훈련

### 3.1 기본 선형 모델

- 기본 선형모델(정규방정식)

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# 교차검증을 사용하지 않은 방법 (잘못된 방법)
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

y_pred = lin_reg.predict(X_test)

rmse = mean_squared_error(y_test, y_pred, squared = False)  # MSE의 제곱근을 구하려면 squared = False
rmse
```

```
4.928602182665355
```

```python
from sklearn.model_selection import cross_val_score

lin_reg = LinearRegression()

# 교차검증을 사용한 경우 (올바른 방법)
scores = cross_val_score(lin_reg, X_train, y_train, scoring = 'neg_mean_squared_error', cv = 5)
lin_reg_rmse = np.sqrt((-scores).mean())
lin_reg_rmse
```

```
4.86358080742005
```

- 기본 선형모델(경사하강법 + 특성스케일링)

```python
np.random.seed(42)
```

```python
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler  # 평균을 0, 분산을 1로 변환
```

```python
# 교차검증 사용

std_scaler = StandardScaler()
X_train_scaled = std_scaler.fit_transform(X_train)

sgd_reg = SGDRegressor(penalty = None, random_state = 42)
scores = cross_val_score(sgd_reg, X_train_scaled, y_train, scoring = 'neg_mean_squared_error', cv = 5)
sgd_reg_rmse = np.sqrt((-scores).mean())
sgd_reg_rmse
```

```
4.898581570477037
```

```python
X_train_scaled.mean(), X_train_scaled.std()
```

```
(-9.740875280793452e-17, 1.0)
```

### 3.2 다항 회귀 모델

```python
from sklearn.preprocessing import PolynomialFeatures     # 변환기

poly_features = PolynomialFeatures(degree = 2, include_bias = False)
X_train_poly = poly_features.fit_transform(X_train)

X_train.shape, X_train_poly.shape
```

```
((404, 13), (404, 104))
```

```python
# 다항회귀 (정규방정식)
lin_reg = LinearRegression()

# 교차검증
scores = cross_val_score(lin_reg, X_train_poly, y_train, scoring = 'neg_mean_squared_error', cv = 5)
poly_lin_reg_rmse = np.sqrt((-scores).mean())
poly_lin_reg_rmse
```

```
4.349154691332248
```

```python
# 다항회귀 (경사하강법)
# (1) Poly(제곱특성 추가) -> (2) STD scale(표준화) -> (3) SGDRegressor (경사하강법)

# (1) Poly(제곱특성 추가)

poly_features = PolynomialFeatures(degree = 2, include_bias = False)
X_train_poly = poly_features.fit_transform(X_train)


# (2) STD scale(표준화)

std_scaler = StandardScaler()
X_train_poly_scaled = std_scaler.fit_transform(X_train_poly)


# (3) SGDRegressor (경사하강법)

sgd_reg = SGDRegressor(penalty = None, random_state = 42)
scores = cross_val_score(sgd_reg, X_train_poly_scaled, y_train, scoring = 'neg_mean_squared_error', cv = 5)
sgd_reg_rmse = np.sqrt((-scores).mean())
sgd_reg_rmse
```

```
3.8507394341607575
```

### pipeline으로 이어버림 (모델까지도 이을 수 있음)

```python
from sklearn.pipeline import Pipeline
```

```python
# 다항회귀 (경사하강법) with Pipeline
# (1) Poly(제곱특성 추가) -> (2) STD scale(표준화) -> (3) SGDRegressor (경사하강법)

# (1) Poly(제곱특성 추가) -> (2) STD scale(표준화)

poly_std_pipelin = Pipeline([
                    ('poly', PolynomialFeatures(degree = 2, include_bias = False)),
                    ('std_scaler', StandardScaler())
                    ])

X_train_poly_scaled = poly_std_pipelin.fit_transform(X_train)


# (3) SGDRegressor (경사하강법)

sgd_reg = SGDRegressor(penalty = None, random_state = 42)
scores = cross_val_score(sgd_reg, X_train_poly_scaled, y_train, scoring = 'neg_mean_squared_error', cv = 5)
sgd_reg_rmse = np.sqrt((-scores).mean())
sgd_reg_rmse
```

```
3.8507394341607575
```

### 3.3 규제모델

- **모델 파라미터** 규제가 되는지 확인(교차검증 사용하지 않음)

```python
from sklearn.linear_model import Ridge, Lasso, ElasticNet
```

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
```

```
LinearRegression()
```

```python
X_train.shape
```

```
(404, 13)
```

```python
lin_reg.intercept_, lin_reg.coef_
```

```
(30.24675099392408,
 array([-1.13055924e-01,  3.01104641e-02,  4.03807204e-02,  2.78443820e+00,
        -1.72026334e+01,  4.43883520e+00, -6.29636221e-03, -1.44786537e+00,
         2.62429736e-01, -1.06467863e-02, -9.15456240e-01,  1.23513347e-02,
        -5.08571424e-01]))
```

```python
lin_coef = pd.Series(lin_reg.coef_, index = X_train.columns)
lin_coef_sort = lin_coef.sort_values(ascending = False)
sns.barplot(x = lin_coef_sort.values, y = lin_coef_sort.index)
```

```
<AxesSubplot:>
```

![image](https://user-images.githubusercontent.com/84713532/205041359-03cdd943-e2e0-468c-a9fa-6a89905cbf97.png)


- 릿지 회귀(Ridge)

```python
alphas = [0, 0.1, 1, 10, 100]
coef_df = pd.DataFrame()
for alpha in alphas:
    ridge_reg = Ridge(alpha = alpha, random_state = 42)
    ridge_reg.fit(X_train, y_train)

    ridge_coef = pd.Series(ridge_reg.coef_, index = X_train.columns)
    ridge_coef_sort = ridge_coef.sort_values(ascending = False)

    column = 'alpha: ' + str(alpha)
    coef_df[column] = ridge_coef_sort

coef_df
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alpha: 0</th>
      <th>alpha: 0.1</th>
      <th>alpha: 1</th>
      <th>alpha: 10</th>
      <th>alpha: 100</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>RM</th>
      <td>4.438835</td>
      <td>4.445779</td>
      <td>4.464505</td>
      <td>4.195326</td>
      <td>2.438815</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>2.784438</td>
      <td>2.750333</td>
      <td>2.545470</td>
      <td>1.813291</td>
      <td>0.550702</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.262430</td>
      <td>0.260043</td>
      <td>0.248882</td>
      <td>0.248031</td>
      <td>0.299014</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>0.040381</td>
      <td>0.034896</td>
      <td>0.007498</td>
      <td>-0.026277</td>
      <td>-0.048625</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>0.030110</td>
      <td>0.030459</td>
      <td>0.032271</td>
      <td>0.035552</td>
      <td>0.039892</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.012351</td>
      <td>0.012400</td>
      <td>0.012642</td>
      <td>0.012833</td>
      <td>0.011951</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>-0.006296</td>
      <td>-0.007305</td>
      <td>-0.012191</td>
      <td>-0.015341</td>
      <td>0.000545</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>-0.010647</td>
      <td>-0.010780</td>
      <td>-0.011475</td>
      <td>-0.012744</td>
      <td>-0.014630</td>
    </tr>
    <tr>
      <th>CRIM</th>
      <td>-0.113056</td>
      <td>-0.112400</td>
      <td>-0.109234</td>
      <td>-0.107134</td>
      <td>-0.110765</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>-0.508571</td>
      <td>-0.510902</td>
      <td>-0.523833</td>
      <td>-0.561835</td>
      <td>-0.689539</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>-0.915456</td>
      <td>-0.900771</td>
      <td>-0.828604</td>
      <td>-0.761769</td>
      <td>-0.817852</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-1.447865</td>
      <td>-1.429608</td>
      <td>-1.338700</td>
      <td>-1.232621</td>
      <td>-1.129400</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>-17.202633</td>
      <td>-15.924459</td>
      <td>-9.537952</td>
      <td>-1.889245</td>
      <td>-0.197859</td>
    </tr>
  </tbody>
</table>
</div>

```python
# 릿지회귀 모델 (L2 규제) - 경사하강법으로 해를 구함

# 규제 없이
sgd_reg = SGDRegressor(penalty = None, random_state = 42)
sgd_reg.fit(X_train, y_train)  
print(sgd_reg.intercept_, sgd_reg.coef_)

# 규제 추가
sgd_reg_l2 = SGDRegressor(penalty = 'l2', alpha = 0.1, random_state = 42)
sgd_reg_l2.fit(X_train, y_train)
print(sgd_reg_l2.intercept_, sgd_reg_l2.coef_)
```

```
[-3.03697309e+09] [ 1.96158882e+11 -4.37426320e+10  2.46260854e+11  3.90764013e+10
  1.33614271e+10  9.42690473e+10  1.37150171e+11 -8.36352963e+10
  1.32613262e+11  2.61743760e+11 -1.74038703e+11  1.90495835e+11
  4.35886010e+11]
[2.30881072e+10] [-5.42774540e+11 -2.40598302e+11 -1.92927130e+11 -1.70039845e+10
  4.77798504e+09  4.18449263e+10 -1.55267196e+11  1.50425226e+11
 -3.62810997e+11 -7.81007337e+10  1.72580814e+11 -4.81196425e+11
  1.67977759e+11]
```

- 라쏘 회귀(Lasso)

```python
alphas = [0.05, 0.1, 0.2, 0.5, 1]
coef_df = pd.DataFrame()
for alpha in alphas:
    Lasso_reg = Lasso(alpha = alpha, random_state = 42)
    Lasso_reg.fit(X_train, y_train)

    Lasso_coef = pd.Series(Lasso_reg.coef_, index = X_train.columns)
    Lasso_coef_sort = Lasso_coef.sort_values(ascending = False)

    column = 'alpha: ' + str(alpha)
    coef_df[column] = Lasso_coef_sort

coef_df
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alpha: 0.05</th>
      <th>alpha: 0.1</th>
      <th>alpha: 0.2</th>
      <th>alpha: 0.5</th>
      <th>alpha: 1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>RM</th>
      <td>4.443676</td>
      <td>4.311687</td>
      <td>4.026917</td>
      <td>3.129886</td>
      <td>1.630489</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>1.704029</td>
      <td>0.919952</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.234443</td>
      <td>0.239237</td>
      <td>0.245289</td>
      <td>0.236596</td>
      <td>0.219654</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>0.034602</td>
      <td>0.034893</td>
      <td>0.034848</td>
      <td>0.032640</td>
      <td>0.028501</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.013035</td>
      <td>0.013091</td>
      <td>0.013039</td>
      <td>0.012350</td>
      <td>0.011181</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>-0.012599</td>
      <td>-0.012962</td>
      <td>-0.013317</td>
      <td>-0.013032</td>
      <td>-0.012286</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>-0.017338</td>
      <td>-0.015126</td>
      <td>-0.010294</td>
      <td>0.000000</td>
      <td>0.016395</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>-0.023023</td>
      <td>-0.016785</td>
      <td>-0.005376</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>CRIM</th>
      <td>-0.104256</td>
      <td>-0.104157</td>
      <td>-0.103020</td>
      <td>-0.093034</td>
      <td>-0.076609</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>-0.524613</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>-0.549276</td>
      <td>-0.564674</td>
      <td>-0.590514</td>
      <td>-0.649984</td>
      <td>-0.747107</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>-0.729013</td>
      <td>-0.732247</td>
      <td>-0.741718</td>
      <td>-0.729229</td>
      <td>-0.708582</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-1.183960</td>
      <td>-1.151487</td>
      <td>-1.094868</td>
      <td>-0.915255</td>
      <td>-0.630858</td>
    </tr>
  </tbody>
</table>
</div>

- 엘라스틱텟(ElasticNet)

```python
# ElasticNet (L1 규제, L2 규제)
from sklearn.linear_model import ElasticNet

elastic_reg = ElasticNet(alpha = 0.1, l1_ratio = 0.5, random_state = 42)
elastic_reg.fit(X_train, y_train)
elastic_reg.intercept_, elastic_reg.coef_
```

```
(24.453646004331702,
 array([-0.10685304,  0.0370152 , -0.03089955,  0.97722083, -0.01993179,
         3.76434053, -0.01170315, -1.17602006,  0.25844329, -0.0134792 ,
        -0.76162739,  0.0127458 , -0.60005149]))
```

```python
# 규제 없이
sgd_reg = SGDRegressor(penalty = None, random_state = 42)
sgd_reg.fit(X_train, y_train)    # y.ravel(), y.flatten()은 데이터를 일차원으로 만들어줌
print(sgd_reg.intercept_, sgd_reg.coef_)

# 규제 추가
sgd_reg_l1l2 = SGDRegressor(penalty = 'elasticnet', alpha = 0.1, random_state = 42)
sgd_reg_l1l2.fit(X_train, y_train)
print(sgd_reg_l1l2.intercept_, sgd_reg_l1l2.coef_)
```

```
[-3.03697309e+09] [ 1.96158882e+11 -4.37426320e+10  2.46260854e+11  3.90764013e+10
  1.33614271e+10  9.42690473e+10  1.37150171e+11 -8.36352963e+10
  1.32613262e+11  2.61743760e+11 -1.74038703e+11  1.90495835e+11
  4.35886010e+11]
[3.81886933e+10] [ 1.71763195e+11 -2.01955893e+11 -2.65900737e+10  7.77143325e+08
  9.26623089e+09  1.14534431e+11 -1.04361834e+11  1.06121350e+11
 -3.43992195e+10  1.20757337e+10  1.97798740e+11 -3.62252830e+11
  5.94183847e+10]
```

```python
alphas = [0.05, 0.1, 0.2, 0.5, 1]
coef_df = pd.DataFrame()
for alpha in alphas:
    ElasticNet_reg = ElasticNet(alpha = alpha, random_state = 42)
    ElasticNet_reg.fit(X_train, y_train)

    ElasticNet_coef = pd.Series(ElasticNet_reg.coef_, index = X_train.columns)
    ElasticNet_coef_sort = ElasticNet_coef.sort_values(ascending = False)

    column = 'alpha: ' + str(alpha)
    coef_df[column] =ElasticNet_coef_sort

coef_df
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

```
.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
```

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alpha: 0.05</th>
      <th>alpha: 0.1</th>
      <th>alpha: 0.2</th>
      <th>alpha: 0.5</th>
      <th>alpha: 1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>RM</th>
      <td>4.134773</td>
      <td>3.764341</td>
      <td>3.160552</td>
      <td>2.051658</td>
      <td>1.162996</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>1.521003</td>
      <td>0.977221</td>
      <td>0.404020</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>0.247966</td>
      <td>0.258443</td>
      <td>0.273963</td>
      <td>0.287364</td>
      <td>0.275980</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>0.035809</td>
      <td>0.037015</td>
      <td>0.038071</td>
      <td>0.037961</td>
      <td>0.035571</td>
    </tr>
    <tr>
      <th>B</th>
      <td>0.012867</td>
      <td>0.012746</td>
      <td>0.012439</td>
      <td>0.011721</td>
      <td>0.011013</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>-0.012941</td>
      <td>-0.013479</td>
      <td>-0.014028</td>
      <td>-0.014505</td>
      <td>-0.014273</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>-0.014885</td>
      <td>-0.011703</td>
      <td>-0.005211</td>
      <td>0.006508</td>
      <td>0.018591</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>-0.027025</td>
      <td>-0.030900</td>
      <td>-0.031594</td>
      <td>-0.030560</td>
      <td>-0.020130</td>
    </tr>
    <tr>
      <th>CRIM</th>
      <td>-0.106450</td>
      <td>-0.106853</td>
      <td>-0.107092</td>
      <td>-0.103047</td>
      <td>-0.093299</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>-0.569848</td>
      <td>-0.600051</td>
      <td>-0.644219</td>
      <td>-0.719262</td>
      <td>-0.775576</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>-0.753753</td>
      <td>-0.761627</td>
      <td>-0.783677</td>
      <td>-0.794361</td>
      <td>-0.752705</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>-0.959210</td>
      <td>-0.019932</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>-1.205832</td>
      <td>-1.176020</td>
      <td>-1.132253</td>
      <td>-0.987340</td>
      <td>-0.755423</td>
    </tr>
  </tbody>
</table>
</div>
